---
title: "Difficulty levels for 19 new items for age range 0-4 Years"
author: "Stef van Buuren, Elise Dusseldorp, Bernice Doove"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{D-score 0-4 Years}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Objective

The D-score (Jacobusse et al. 2006; Van Buuren, 2014) was built on 
items taken from the so-called \emph{Dutch Developmental Instrument} (DDI), 
also known as the \emph{Van Wiechen Schema}. This scheme which covers ages 
0-4 years, and has a total of 75 item. The data used to 
calibrate the D-score came from the SMOCC study (Herngreen et al, 1993), which 
covers only the age range 0-2 years, so the SMOCC study was limited to 57 of the 
75 items. 

A new dataset, the `doove` data, has recently become available. This dataset collects 
DDI items in the age range 2-4 years. This vignette shows how the 57-items 
based D-score can be extended for use into the ages 2-4 years.

## Data

The data we need are stored in the `ddata` package. The `dscore` package (this package) contains 
functions for fitting and calibrating the Rasch model, and estimating the D-score from 
data using the built-in item bank. We wish to extend this item bank here.

```{r libraries}
library("ddata")
library("dscore")
library("dplyr", warn.conflicts = FALSE)
```

We collect the various objects as follows:

```{r readdata}
# fetch published tau (Van Buuren 2014, Table 2) from dscore::itembank
pub_tau <- filter(itembank, !is.na(lex.dutch1983)) %>% .$tau
names(pub_tau) <- filter(itembank, !is.na(lex.dutch1983)) %>% .$lex.jam

# extract what we need from ddata::NL and ddata::NL2
# skip v40 in NL2 because it has only one fail
smocc_vars <- c("country", "study", "id", "wave", "agedays", 
                paste0("n", 1:57))
doove_vars <- c("country", "study", "id", "wave", "agedays",
                "n38", "n39", "n44", "n45", "n51", "n52", "n53", "v20", 
                 "v21", "v22", "v23", "v24", "v25", "v26", "v27", "n2", 
                 "n47", "v42", "n55", "n56", "v45", "v46", "v47",
                 "v48", "v49", "v50", "n35", "n42", "n43", "n49", "n50",
                 "n57", "v72", "v73", "v74", "v75")
smocc <- select_(NL, .dots = smocc_vars)
doove <- select_(NL2, .dots = doove_vars)       
```

The naming scheme follows the `lex.jam` lexicon, where the original 57 items in the 
SMOCC data have variables names `n1` to `n57`, and where the new items for ages 
2-4 years have variable names starting with a `v`. More details on the `doove` data can be found 
by `help(NL2)`. Item `v40` turned out to have only one fail, and was taken out of the analysis.

A `1` in the data means a *pass*, a `0` means a *fail*.

Note there is some overlap between the items collected in `smocc` and `doove`. 
We assume here that the items are comparable between both studies. This assumption 
allows us to calibrate both samples to each other. 

## Combined data

It is possible to work either with the separate data sources, 
as well as with the combined data. We use the `bind_rows()` function from the 
`dplyr` package to stack the data.

```{r combine}
# prevent bind_rows() warning: Unequal factor levels
smocc$study <- as.character(smocc$study)
doove$study <- as.character(doove$study)

# combine data
wd <- dplyr::bind_rows(smocc, doove)
```

## Scenario 1: Recreate published estimates, only old data

One may recreate the published estimates (Van Buuren 2014, Table 2) 
for items `n1` to `n57` using the SMOCC data. After estimation, the difficulties 
need to be anchored by means of the `anchor()` function.

```{r fit1}
fit1 <- rasch(select(smocc, -(1:5)))
tau1 <- anchor(get_diff(fit1), items = c("n12", "n26"))
round(tau1, 1)
```

The estimated and recalculated difficulty estimates in `tau1` are essentially the same.

```{r plot1, fig.height=6, fig.width=6}
cor(pub_tau, tau1)
plot(x = pub_tau, y = pub_tau - tau1,
     xlab = "Published", ylab = "Published - estimated",
     main = "Difficulties items n1:n57")
abline(0, 0, lty = 2)
```


## Scenario 2: New difficulty estimates, combined data

Suppose we repeat exactly the same model fitting procedure on the combined data. We are then 
able to obtain difficulty estimates on the new items, as follows:

```{r fit2}
fit2 <- rasch(select(wd, -(1:5)))
tau2 <- anchor(get_diff(fit2), items = c("n12", "n26"))
round(tau2)
```

As expected, the new items are among the most difficult ones. Note that we cannot 
exactly recreate the old estimates. The following graph represents the differences
with the published estimates.

```{r plot2, fig.height=6, fig.width=6}
plot(x = pub_tau, y = pub_tau - tau2[paste0("n", 1:57)],
     xlab = "Published", ylab = "Published - estimated",
     main = "Difficulties items n1:n57")
abline(0, 0, lty = 2)
```

It is possible to replace the published estimates by the new estimates (assuming that 
the model fits well). However, replacing the estimates would effectively introduce
a new measurement scale, and hence invalidate work already done based on the current 
scale. 

## Scenario 3: Fixed difficulty estimates, combined data

An alternative option is to estimate the new difficulties while keeping the old ones fixed. 
Such a strategy would really extend the measurement scale, rather than replacing it by 
another, only marginally different, scale. 

Here we fixed the estimates as obtained in `fit1`, and re-estimate the Rasch model
only for the new items.


```{r fit3}
fit3 <- rasch(select(wd, -(1:5)), b_fixed = get_diff(fit1))
tau3 <- anchor(get_diff(fit3), items = c("n12", "n26"))
round(tau3, 1)
```

Note that we difficulty estimates in `tau3` are equivalent to the published estimates
given before, but we also obtain estimates for the new items from the restricted 
Rasch model.

```{r plot3, fig.height=6, fig.width=6}
plot(x = pub_tau, y = pub_tau - tau3[paste0("n", 1:57)],
     xlab = "Published", ylab = "Tau fixed (combined data)",
     main = "Difficulties items n1:n57")
abline(0, 0, lty = 2)
```

## Scenario 4: Fixed difficulty estimates, only new data

Finally, we may arrive at the same solution if we do not have access to the original 
data. The following code fits the same model as in scenario 3, but now we use 
only the Doove data.

```{r fit4}
linked <- names(doove)[names(doove) %in% paste0("n", 1:57)]
new    <- names(doove)[names(doove) %in% paste0("v", 1:100)]
fixed_beta <- get_diff(fit1)[names(get_diff(fit1)) %in% linked]
fit4 <- rasch(select(doove, -(1:5)), b_fixed = fixed_beta)
# tau4 <- anchor(get_diff(fit4), items = c("n12", "n26"))
```

Because the anchor items were not observed in the `doove` data, `anchor()`
fails to calculate the difficulties in the D-score scale. This requires us to resort to 
special calibration techniques that we not needed in scenario 3.

As expected, the estimates for the new items are nevertheless identical to those found in scenario 3.

```{r plot4, fig.height=6, fig.width=6}
plot(x = fit3$b[new], y = fit3$b[new] - fit4$b[new],
     xlab = "beta3", ylab = "beta3 - beta4",
     main = "Difficulties - new items")
abline(0, 0, lty = 2)
```


## Wrap up

The item bank in the `dscore` package was extended by the estimates obtained from 
scenario 3. The extended item bank can now be used to calculate the D-score when 
scores on one or more of the new items are available. 

What remains to be done is the study the spread of the D-score at a given age, and to condense the result into a reference for normal development. Also, we did not investigate the quality of the fit of the Rasch model. Such would be needed to make a more informed assement of the measurement properties of the extended scale.

